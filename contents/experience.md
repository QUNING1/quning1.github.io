## ğŸ’¼ Internship Experience

[ğŸ‡¨ğŸ‡³ ä¸­æ–‡](#-ç®—æ³•å®ä¹ ç”Ÿ) | [ğŸ‡ºğŸ‡¸ English](#-algorithm-intern)

---

### **ç®—æ³•å®ä¹ ç”Ÿ**

#### **2025å¹´5æœˆ â€“ 2025å¹´9æœˆ | å­—èŠ‚è·³åŠ¨ ï½œ Data-æ¨è**

##### ä¸»è¦è´¡çŒ®
**é¡¹ç›®ä¸€ï¼šå¤´æ¡pushæ–‡æ¡ˆå®¡æ ¸æ¨¡å‹**
- è®¾è®¡å¹¶æ„å»ºæ–‡æ¡ˆå®¡æ ¸benchmarkï¼Œæ˜ç¡®è¯„ä¼°ç»´åº¦ä¸æŒ‡æ ‡ï¼Œäº§å‡ºé«˜è´¨é‡è®­ç»ƒä¸æµ‹è¯•æ•°æ®é›†ï¼Œè®­ç»ƒDoubao-1.5-Proæ¨¡å‹ï¼Œåœ¨æµ‹è¯•é›†ä¸ŠP@R=0.8è¾¾åˆ°83.2%ï¼Œè¯¯ä¼¤ç‡æ˜¾è‘—ä¸‹é™è‡³10.8%ã€‚
- ä½¿ç”¨CoT+SFTæ··åˆè®­ç»ƒç­–ç•¥ï¼Œå¼•å…¥å…«æ®µå¼CoTæ•°æ®æå‡æ¨¡å‹å¤æ‚æ¨ç†èƒ½åŠ›ï¼Œå¹³å‡å¸¦æ¥3.8%çš„Precisionæå‡å’Œ2.8%çš„è¯¯ä¼¤ç‡ä¸‹é™ï¼Œæœ€ç»ˆæ¨åŠ¨æ¨¡å‹æˆåŠŸä¸Šçº¿ã€‚

**é¡¹ç›®äºŒï¼šå¤šæ¨¡æ€è¡¨å¾é¢„è®­ç»ƒ**
- èåˆæ¨èã€æœç´¢ã€å†…å®¹å®¡æ ¸ç­‰åœºæ™¯çš„å¤šæºå¼‚æ„æ•°æ®ï¼Œæ„å»ºåƒä¸‡çº§è§„æ¨¡çš„å¤šæ¨¡æ€è®­ç»ƒæ ·æœ¬ï¼›æ‰©å±•æ¨¡å‹è¾“å…¥èƒ½åŠ›ï¼Œä½¿å…¶æ”¯æŒæœ€é•¿8kçš„æ–‡æœ¬åºåˆ—å’Œ8å¸§å›¾åƒè¾“å…¥ï¼Œå¢å¼ºå¯¹é•¿æ–‡æœ¬å’Œè§†é¢‘ç±»å†…å®¹çš„å»ºæ¨¡èƒ½åŠ›ã€‚
- é‡‡ç”¨VLMä½œä¸ºbackboneï¼Œå¼•å…¥åŒå‘æ³¨æ„åŠ›æœºåˆ¶å¹¶å°†æ¯ä¸ªtokençš„éšçŠ¶æ€é€šè¿‡mean poolingä½œä¸ºåºåˆ—åµŒå…¥ï¼›é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ï¼šç¬¬ä¸€é˜¶æ®µé€šè¿‡æ— ç›‘ç£å¯¹æ¯”å­¦ä¹ å»ºç«‹åŸºç¡€è¯­ä¹‰è¡¨å¾ï¼Œç¬¬äºŒé˜¶æ®µç»“åˆé«˜è´¨é‡pairæ•°æ®ä¸å›°éš¾è´Ÿæ ·æœ¬æŒ–æ˜ï¼Œè¿›ä¸€æ­¥æå‡å¤šæ¨¡æ€å¯¹é½ä¸åˆ¤åˆ«èƒ½åŠ›ã€‚
- å¤šæ¨¡æ€æ£€ç´¢ä»»åŠ¡ä¸Šï¼ŒNDCG@10æŒ‡æ ‡ä¸Šä»71.2%æå‡è‡³80.4%ï¼›æ¨èCTRä»»åŠ¡ä¸­ï¼ŒAUCæŒ‡æ ‡æå‡2.1%ï¼›å¤šæ¨¡æ€åˆ†ç±»ä»»åŠ¡ä¸­ï¼ŒP@R=0.5ç”±17.5%æå‡è‡³19.0%ã€‚

---

#### **2025å¹´1æœˆ â€“ 2025å¹´5æœˆ | ç™¾åº¦ ï½œ æ–‡å¿ƒä¸€è¨€**

##### ä¸»è¦è´¡çŒ®
- æå‡ºé«˜è´¨é‡å¤šæ¨¡æ€åå¥½æ•°æ®è‡ªåŠ¨åˆæˆæ–¹æ¡ˆï¼Œè®¾è®¡å¤šè½®è¿‡æ»¤æœºåˆ¶ï¼šquery-captioné‡åˆåº¦ç­›é€‰ã€å›¾ç‰‡é‡è¦ä¿¡æ¯æ©ç ä¸å›å¤é‡‡æ ·ã€pairæ‰“åˆ†è¿‡æ»¤ï¼ˆåŸºäºå¥–åŠ±æ¨¡å‹æˆ–äººå·¥æ ‡æ³¨ï¼‰ï¼Œæå‡æ•°æ®è´¨é‡ã€‚
- åˆæˆæ•°æ®æ•ˆæœæ˜¾è‘—ï¼šæ­£è´Ÿæ ·æœ¬ç»äººå·¥æ ‡æ³¨å‡†ç¡®ç‡è¾¾99%+ï¼›DPOå®éªŒä¸­ï¼Œä¼˜åŒ–åæ¨¡å‹ç›¸è¾ƒbaseæ¨¡å‹åœ¨GSBæŒ‡æ ‡ä¸Šè¾¾æˆ38.5% : 61.5% : 0ä¼˜åŠ¿åˆ†å¸ƒã€‚

---

#### **2024å¹´10æœˆ â€“ 2025å¹´1æœˆ | ç¾å›¢ ï½œ æ ¸å¿ƒæœ¬åœ°å•†ä¸š**

##### ä¸»è¦è´¡çŒ®
- è´Ÿè´£IMç•™èµ„æœºå™¨äººï¼ˆå¤œé—´æ™ºèƒ½å®¢æœï¼‰éƒ¨åˆ†é“¾è·¯çš„è®¾è®¡ä¸ä¼˜åŒ–ï¼Œå¹¶æ¨åŠ¨äº§å“æˆåŠŸä¸Šçº¿è‡³ç¾å›¢APPã€‚
- é’ˆå¯¹ä¸šåŠ¡åœºæ™¯æ„å»ºæ•°æ®å¾®è°ƒçš„embeddingæ¨¡å‹ (bge-large-zh-v1.5)ï¼Œä½¿FAQæ•´ä½“å¬å›ç‡æå‡15%ã€‚
- è´Ÿè´£å›å¤æ¨¡å‹SFTçš„è¿­ä»£ä¼˜åŒ–ï¼Œæ•´åˆçœŸå®å†å²å¯¹è¯ã€LLMåŠè‡ªåŠ¨ç”Ÿæˆå¯¹è¯ã€å…œåº•è¯æœ¯ç­‰æ•°æ®ï¼Œå¯¹è¯å‡†ç¡®ç‡ç”±39%æé«˜è‡³83%ã€‚
- æ¢ç´¢CPT+SFTçš„å›å¤æ¨¡å‹(14B)è®­ç»ƒæ–¹å¼ï¼Œç»“åˆçœŸå®å¯¹è¯ä¸åŒ»ç¾çŸ¥è¯†åº“å¹¶è¿›è¡Œè¿‡æ»¤ï¼Œè¡¨ç°ä¼˜äºåªåšSFTçš„72Bæ¨¡å‹ï¼Œé™ä½äº†çº¿ä¸Šæ¨ç†æˆæœ¬ã€‚
- åŸºäºçº¿ä¸ŠåŠè‡ªæµ‹çš„bad caseï¼Œæ„å»ºå¤šæ ·åŒ–è®­ç»ƒæ ·æœ¬ï¼Œè¿­ä»£ä¼˜åŒ–æ„å›¾è¯†åˆ«å’Œå¹»è§‰æ£€æµ‹ç­‰å…¶ä»–æ ¸å¿ƒæ¨¡å—ã€‚

---

### **Algorithm Intern**

#### **May 2025 â€“ Sep 2025 | ByteDance ï½œ Data-Recommendation**

##### Key Contributions
**Project 1: Push Content Moderation Model**
- Designed and built a benchmark for content moderation, defining evaluation metrics and producing high-quality datasets; trained **Doubao-1.5-Pro**, achieving **83.2% P@R=0.8** with false positive rate reduced to **10.8%**.
- Applied a **CoT+SFT hybrid training strategy** with 8-step CoT data, enhancing complex reasoning and bringing **+3.8% Precision** and **-2.8% false positives**, leading to successful deployment.

**Project 2: Multimodal Representation Pretraining**
- Integrated heterogeneous data from recommendation, search, and moderation to build tens of millions of multimodal samples; extended model input to **8k text tokens and 8 video frames**.
- Adopted **VLM backbone** with bi-directional attention and mean pooling embeddings; applied a **two-stage training**: (1) unsupervised contrastive learning for base semantics, (2) supervised fine-tuning with high-quality pairs and hard negatives.
- Results: **NDCG@10 from 71.2% â†’ 80.4%** (retrieval), **+2.1% AUC** (CTR prediction), **P@R=0.5 from 17.5% â†’ 19.0%** (classification).

---

#### **Jan 2025 â€“ May 2025 | Baidu ï½œ ERNIE Bot**

##### Key Contributions
- Proposed an **automatic synthesis pipeline** for multimodal preference data, with multi-stage filtering: queryâ€“caption overlap, key information masking with response sampling, and pair scoring with reward model or human labels.
- Achieved **99%+ accuracy** under human evaluation; in **DPO experiments**, optimized model outperformed base model on GSB metric with a **38.5% : 61.5% : 0** winâ€“tieâ€“loss distribution.

---

#### **Oct 2024 â€“ Jan 2025 | Meituan ï½œ Core Local Commerce**

##### Key Contributions
- Designed and optimized part of the **IM Lead-Collection Bot** (nighttime customer service), successfully launched on Meituan App.
- Fine-tuned **bge-large-zh-v1.5 embedding model**, improving FAQ recall by **+15%**.
- Optimized **response model (SFT)** with real dialogues, semi-automatic LLM data, and fallback responses, raising accuracy **39% â†’ 83%**.
- Explored **CPT+SFT** training for 14B model with domain-specific KB, outperforming a 72B SFT-only model while reducing inference cost.
- Built diverse samples from bad cases to iteratively improve **intent recognition** and **hallucination detection**.
